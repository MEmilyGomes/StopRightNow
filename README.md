<div align="center">
  <img src="Imagens/logo_Ilum-CNPEM.png" alt="Descri√ß√£o da imagem" width="1000"/>
</div>

<h1 align="center"> Stop right now, thank you very much ü§öüíÉ:</h1>
<h2 align="center">Implementa√ß√£o da  estrat√©gia de Parada Antecipada</h2>

<p align="center"><strong>Autoras:</strong> Lorena Ribeiro Nascimento e Maria Emily Nayla Gomes da Silva</p>
<p align="center"><strong>Orientador:</strong> Prof. Dr. Daniel R. Cassar</p>


<p align="center">
<img loading="lazy" src="http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge"/>
</p>


## üìù Descri√ß√£o
<p align="justify">
Nesse projeto, implementou-se a t√©cnica de Parada Antecipada (<i>Early Stopping</i>) no treinamento de uma rede neural convolucional (CNN) implementada em PyTorch com os dados do dataset MNIST. Essa t√©cnica avalia o erro de valida√ß√£o em cada √©poca de treinamento e, caso ocorra um aumento do erro ‚Äî ou seja, esse valor seja superior ao intervalo m√°ximo permitido, definido pelo hiperpar√¢metro <code>DELTA_MINIMO</code> ‚Äî durante a quantidade m√°xima de vezes definida pela <code>PACIENCIA</code>, o treinamento ser√° interrompido antes de completar todas as √©pocas previamente estabelecidas. O objetivo dessa t√©cnica √© garantir que o modelo interrompa o treinamento ao atingir um ponto de estabilidade, evitando <i>overfitting</i> e custo computacional desnecess√°rio.
</p>

## üìî Notebooks e arquivos do projeto
* `Imagens/logo_Ilum-CNPEM.png` ‚Äî Logo da institui√ß√£o Ilum - CNPEM.  
* `EarlyStopping.ipynb` ‚Äî Caderno Jupyter principal do projeto.  
* `README.md` ‚Äî Descri√ß√£o geral do projeto.

## üèãÔ∏è‚Äç‚ôÄÔ∏è Implementando a Parada Antecipada (Early Stopping)
<p align="justify">
Para implementar a parada antecipada, criou-se uma classe <code>EarlyStopper</code>, a qual, ao instanciar uma vari√°vel, salva as informa√ß√µes dos hiperpar√¢metros <code>DELTA_MINIMO</code> e <code>PACIENCIA</code>. A classe apresenta um m√©todo, o <code>early_stop</code> que avalia a perda de valida√ß√£o a cada √©poca e registra quando essa perda aumenta em rela√ß√£o √† anterior. Caso o erro aumente por mais √©pocas do que o valor definido por <code>PACIENCIA</code>, o m√©todo retorna verdadeiro e o treinamento da rede √© interrompido.
</p>

`````Python
class EarlyStopper:
    def __init__(self, PACIENCIA, DELTA_MINIMO):
        self.patience = PACIENCIA
        self.min_delta = DELTA_MINIMO
        self.counter = 0
        self.min_validation_loss = float('inf')

    def early_stop(self, perda_validacao):
        if perda_validacao < self.min_validation_loss:
            self.min_validation_loss = perda_validacao
            self.counter = 0
        elif perda_validacao >= (self.min_validation_loss + self.min_delta): 
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
`````

## üòÅ Conclus√£o
<p align="justify">
A parada antecipada foi devidamente implementada, sendo definido o treinamento por 25 √©pocas, mas interrompido na 23¬™. A CNN, implementada com PyTorch e utilizando os dados do MNIST, atingiu uma acur√°cia de 99%. Observou-se que a defini√ß√£o do <i>delta</i> m√≠nimo √© bastante relevante e deve ser ajustado conforme o comportamento da rede. No nosso caso, como a varia√ß√£o do erro ocorria em valores muito baixos, o <i>delta</i> foi proporcional a essa varia√ß√£o. Portanto, sendo uma implementa√ß√£o simples da t√©cnica, que resultou em um modelo n√£o sobreajustado e com consumo eficiente de recursos computacionais, conclui-se que a parada antecipada √© uma t√©cnica bastante relevante para ser aplicada.
</p>

## üñáÔ∏è Informa√ß√µes t√©cnicas
* Linguagem de programa√ß√£o: `Python 3.9`
* Software:  `Jupyter Notebook`
* **Bibliotecas e M√≥dulos:** `torch`, `torchvision`, `torchvision.datasets`, `torchvision.transforms`, `torch.utils.data.random_split`, `torch.utils.data.DataLoader`, `torch.nn`, `torch.nn.functional`, `torch.optim`, `matplotlib.pyplot`, `os`


## üß† Contribui√ß√µes dos Colaboradores
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/172424739?v=4" width=115><br><sub>Lorena Ribeiro Nascimento</sub>](https://github.com/Lorena881)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>]()<br> [<sub>Linkedin</sub>]() | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/172424897?v=4" width=115><br><sub> Maria Emily Nayla</sub>](https://github.com/MEmilyGomes)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>](http://lattes.cnpq.br/9482558334105708)<br> | [<img loading="lazy" src="https://github.com/user-attachments/assets/463d4753-7fa4-4a42-aa54-409e4150bb51" width=115><br> <sub> Prof. Dr. Daniel R. Cassar </sub>](https://github.com/drcassar)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>](http://lattes.cnpq.br/1717397276752482) | 
| :---: | :---: | :---: | 

#### Para o Projeto:
* Lorena Ribeiro: Constru√ß√£o da CNN, implementa√ß√£o da parada antecipada e coment√°rios no notebook principal.
* Emily Gomes: Constru√ß√£o da CNN e implementa√ß√£o da parada antecipada.

#### Para o Reposit√≥rio GitHub:
* Emily Gomes: README.

**Orienta√ß√£o:** Prof. Dr. Daniel R. Cassar.
